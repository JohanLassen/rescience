---
output: github_document
---



<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
library(knitr)
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)


ggplot2::theme_set(ggplot2::theme_classic())

```

# Rescience - Setting up for Reproducible Science 

<!-- badges: start -->
[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://lifecycle.r-lib.org/articles/stages.html#experimental)
<!-- badges: end -->

The goal of rescience is to provide an easy framework to test different preprocessing and machine learning methods while minimizing the risk of overfitting. 

## Installation

You can install the development version of rescience from [GitHub](https://github.com/JohanLassen/rescience) with:

``` r
# install.packages("devtools")
# devtools::install_github("JohanLassen/rescience")
```

## Example

This is a basic example which shows you how to solve a common problem:

```{r example}

library(rescience)
library(tidyverse)

# dataset
head(pneumonia[,1:10])

```

To statistically analyze this data it must undergo (1) selection of important variables including outcome, batch, and technical replicates, (2) preprocessing to ensure that all features and compounds are within the same range of values and to minimize batch effect, (3) perform a machine learning model screening to evaluate which model fits the data best.

Point 2 and 3 requires the analyst to be careful, read more here.


# The simple way to do it
The package is accompanied with a web app that ensures that a broad range of users can confidently use the methods. The app exists as an online version to show case the setup, but we recommend users to install R, Rstudio, and this package to experience the best performance.

To run the app:
```{r}
#run_app()
```

# Diving deeper
The true beauty of the package reveals itself when developing custom scripts and implementing your own functions. 

We strive to include as many different methods as possible to accommodate methodological studies on batch effect, machine learning algorithms, and model interpretation. Hence, it should be as easy as possible to contribute to the package by writing functions that fits the required data format.

For consistency we format data into a R list called ms. The ms list contain the feature values (ms$values) and sample meta data (ms$rowinfo).

# (1) Loading data

In the example of pneumonia we generate the ms the following way:

```{r}

# First convert the pneumonia object to a tibble. 
pneumonia <- tibble(pneumonia)

# Generate list object
ms <- list()

# Assign feature values to ms$values
start_column <- 8 # The first column with feature values
end_column <- ncol(pneumonia) # The last column of the dataset
ms$values <- pneumonia[, start_column:end_column]

# Assign metadata to ms$rowinfo
ms$rowinfo <- pneumonia %>% select(rowid = id, group, age, gender, weight, height, BMI)
```


Now the ms object is made

```{r, echo = F}

# showing first 5 columns
knitr::kable(head(ms$values[,1:5]), caption = 'Feature values', align = "c")

```

```{r, echo = F}

knitr::kable(head(ms$rowinfo), caption = 'Meta Data', align = "r")

```


# Preprocessing
```{r, fig.height=3, fig.width=6, out.width='600px', out.height="300px", fig.align='center', fig.cap='...'}

# fourth root transformation
ms <- transform_fourth_root(ms)

# Probabilistic quotient normalization
ms <- normalize_pqn(ms)

# Visualize distributions of first 10 compounds to see effect of preprocessing
ms$values[,1:5] %>% 
  pivot_longer(cols = everything(), names_to = "Feature") %>%
  mutate(Feature = as.factor(Feature)) %>% 
  ggplot(aes(x=value, fill = Feature)) +
  geom_histogram(position = "identity", alpha = 0.3)
  
```

And if we want to see the PCA plot:

```{r, fig.height=3, fig.width=10, out.width='1000px', out.height="300px", fig.align='center', fig.cap='...'}

# We plot by rowid as the data doesn't have batch info, but the rowid reflects the injection order
plot_pca(ms, color_label = "rowid") 

```

# Machine learning

## Fitting multiple models

```{r, results='hide', warning=FALSE, message=FALSE}

fits <- fit_models(x = ms$values, y=ms$rowinfo$group, methods = c("pls", "glmnet")) #PLS, Elastic net, Random Forest

```

## Obtaining the performance from the models

```{r}

performance <- get_performance(fits)

knitr::kable(performance)

```

## Plotting performance

```{r, fig.height=3, fig.width=7, out.width='700px', out.height="300px", fig.align='center', fig.cap='...'}
plot_performance(fits)
```



